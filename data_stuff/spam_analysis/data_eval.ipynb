{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    }
   ],
   "source": [
    "! ls data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the csv file with our data and set it to a pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train\", sep=\"\\t\", names=[\"true_category\", \"message\", \"label_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This is used to get spam as 1 and ham as 0 so we can use it later\n",
    "for i in range(len(train_data)):\n",
    "    label = train_data['true_category'][i]\n",
    "    if label == 'spam':\n",
    "        train_data.loc[i,\"label_num\"]=int(1)\n",
    "    else:\n",
    "        train_data.loc[i,\"label_num\"]=int(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true_category    object\n",
       "message          object\n",
       "label_num         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.astype({'label_num': 'int64'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_category</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>ham</td>\n",
       "      <td>hiya hows it going in sunny africa? hope u r a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>ham</td>\n",
       "      <td>At WHAT TIME should i come tomorrow</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>spam</td>\n",
       "      <td>Wanna have a laugh? Try CHIT-CHAT on your mobi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4572</th>\n",
       "      <td>ham</td>\n",
       "      <td>CHA QUITEAMUZING THATSCOOL BABE,PROBPOP IN &amp; ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>ham</td>\n",
       "      <td>Omg how did u know what I ate?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4574 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     true_category                                            message  \\\n",
       "0              ham  Go until jurong point, crazy.. Available only ...   \n",
       "1              ham                      Ok lar... Joking wif u oni...   \n",
       "2             spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3              ham  U dun say so early hor... U c already then say...   \n",
       "4              ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...            ...                                                ...   \n",
       "4569           ham  hiya hows it going in sunny africa? hope u r a...   \n",
       "4570           ham                At WHAT TIME should i come tomorrow   \n",
       "4571          spam  Wanna have a laugh? Try CHIT-CHAT on your mobi...   \n",
       "4572           ham  CHA QUITEAMUZING THATSCOOL BABE,PROBPOP IN & ...   \n",
       "4573           ham                     Omg how did u know what I ate?   \n",
       "\n",
       "      label_num  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           1.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "...         ...  \n",
       "4569        0.0  \n",
       "4570        0.0  \n",
       "4571        1.0  \n",
       "4572        0.0  \n",
       "4573        0.0  \n",
       "\n",
       "[4574 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add a new columns to `df` called `predicted_category`\n",
    "- for each row in `df`, if `df[\"predicted_category\"] == df[\"true_category\"]` then you were correct!\n",
    "- for example, if the number of columns that match is 4400, then the accuracy is 4400/4573"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Functions used\n",
    "from version_two import train_func as set_v2\n",
    "from version_two import test_func as alg_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data(algorithm, data):\n",
    "    \"\"\"\n",
    "    This function uses the training data set to pass in the labels and \n",
    "    messages to another function which will create a dictionary that\n",
    "    looks like this.\n",
    "    dict = {\n",
    "        'how': {'spam': 10, 'ham': 450},\n",
    "        'free': {'spam': 154, 'ham': 50},\n",
    "    }\n",
    "    The point of this is to see what the probability of a word being in a\n",
    "    spam labeled message and the word being in a ham labeled message. Once \n",
    "    we have that we can run our classifier algorithm. \n",
    "    \"\"\"\n",
    "    for i in range(len(train_data)):\n",
    "        # get the message \n",
    "        sms = data['message'][i]\n",
    "        # get real label\n",
    "        label = data['true_category'][i]\n",
    "        # call function\n",
    "        algorithm(label, sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(correct_ham, correct_spam, incorrect_ham, incorrect_spam):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    all_incorrect = (incorrect_ham+incorrect_spam)\n",
    "    all_correct = (correct_ham+correct_spam)\n",
    "    precision = (all_correct)/(all_correct+all_incorrect)\n",
    "    recall = (all_correct)/(all_correct+all_incorrect)\n",
    "    \n",
    "    score = (2*((precision*recall)/(precision+recall)))\n",
    "    precision_ham = (correct_ham)/(correct_ham+incorrect_ham)\n",
    "    precision_spam = (correct_spam)/(correct_spam+incorrect_spam)\n",
    "    recall_ham = (correct_ham)/(correct_ham+incorrect_ham) \n",
    "    recall_spam = (correct_spam)/(correct_spam+incorrect_spam) \n",
    "\n",
    "    \n",
    "    ham_score = 2 * ((precision_ham * recall_ham)/(precision_ham+recall_ham))\n",
    "    spam_score = 2 * ((precision_spam * recall_spam)/(precision_spam+recall_spam))\n",
    "    \n",
    "    print(\"f1: \", +score)\n",
    "    print('all correct/2: ',+ (ham_score+spam_score)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_as_spam(sms):\n",
    "    train_func(sms, \"spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(algorithm, data):\n",
    "    \"\"\"\n",
    "    This functon has to run after the set_data function and will determine\n",
    "    the accuracy of the algorithm. \n",
    "    \n",
    "    Since we now have our dictonary with the training data inputed in. We\n",
    "    can now pass in the test data into our algorithm which will return \n",
    "    ham or spam.\n",
    "    \n",
    "    This function accepts an algorithm and a dataset and produces metrics\n",
    "    which show how good the algorithm is. For instance, it prints the percentage\n",
    "    of spam texts that were accurately identified as spam.\n",
    "    \n",
    "    https://en.wikipedia.org/wiki/F1_score\n",
    "    RMSE\n",
    "    \"\"\"\n",
    "    # ammount correct for each label\n",
    "    correct_ham = 0\n",
    "    correct_spam = 0\n",
    "    correct = 0\n",
    "    \n",
    "    spam = len(data.groupby(['true_category']).get_group('spam'))\n",
    "    ham = len(data.groupby(['true_category']).get_group('ham'))\n",
    "    \n",
    "    \n",
    "    len_of_data = len(data)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        # get the message and label \n",
    "        sms = data['message'][i]\n",
    "        label = data['true_category'][i]\n",
    "        \n",
    "        # call function\n",
    "        prediction = algorithm(sms)\n",
    "\n",
    "        \n",
    "        if prediction == label:\n",
    "            # If prediction is correct we add 1\n",
    "            correct += 1\n",
    "            if prediction == 'spam':\n",
    "                # If the predicted label is spam and acutal label\n",
    "                # is spam then we add to amount correct for spam\n",
    "                correct_spam +=1\n",
    "            elif prediction =='ham':\n",
    "                # If the predicted label is ham and acutal label\n",
    "                # is spam then we add to amount correct for ham\n",
    "                correct_ham +=1\n",
    "    \n",
    "    incorrect_ham = ham-correct_ham\n",
    "    incorrect_spam = spam-correct_spam\n",
    "#     get_f1_score(correct_ham, correct_spam, incorrect_ham, incorrect_spam)\n",
    "    print((correct_ham+correct_spam)/2)\n",
    "    print('Correct Ham: ', + correct_ham/ham)\n",
    "    print('Correct Spam: ', + correct_spam/spam)\n",
    "    print('Correct: ', + correct/len_of_data)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Functions used\n",
    "set_data(set_v2, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2174.0\n",
      "Correct Ham:  0.9992424242424243\n",
      "Correct Spam:  0.6368078175895765\n",
      "Correct:  0.9505902929602099\n"
     ]
    }
   ],
   "source": [
    "#### Algorithm results\n",
    "get_accuracy(alg_v2, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Functions used\n",
    "from version_three import train_func as set_v3\n",
    "from version_three import driver_func as alg_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put data in dictonay for use later\n",
    "set_data(set_v3, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1901.5\n",
      "Correct Ham:  0.8282828282828283\n",
      "Correct Spam:  0.8517915309446255\n",
      "Correct:  0.8314385658067337\n"
     ]
    }
   ],
   "source": [
    "# See algorithm results\n",
    "get_accuracy(alg_v3, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Functions used\n",
    "from version_four import train_func as set_v4\n",
    "from version_four import driver_func as alg_v4\n",
    "from version_four import test_func as alg_v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_data(set_v4, train_data)\n",
    "ham_points = {}\n",
    "spam_points = {}\n",
    "def get_points():\n",
    "    for i in range(len(train_data)):\n",
    "        sms = train_data['message'][i]\n",
    "        label = train_data['true_category'][i]\n",
    "        ham, spam =  alg_v4(sms)\n",
    "        if label == 'spam':\n",
    "            spam_points[i] = {'x' : ham, 'y' : spam}\n",
    "        else:\n",
    "            ham_points[i] = {'x' : ham, 'y' : spam}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_x = []\n",
    "spam_y = []\n",
    "for key in spam_points:\n",
    "    val = key\n",
    "    x = spam_points[val]['x']\n",
    "    y = spam_points[val]['y']\n",
    "    spam_x.append(x)\n",
    "    spam_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_x = []\n",
    "ham_y = []\n",
    "for key in ham_points:\n",
    "    val = key\n",
    "    x = ham_points[val]['x']\n",
    "    y = ham_points[val]['y']\n",
    "    ham_x.append(x)\n",
    "    ham_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline \n",
    "# plt.scatter(spam_x, spam_y, color='r')\n",
    "# plt.scatter(ham_x, ham_y, color='b')\n",
    "# plt.xlabel('# Spam')\n",
    "# plt.ylabel('# Ham')\n",
    "# plt.grid(True)\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2264.5\n",
      "Correct Ham:  0.9959595959595959\n",
      "Correct Spam:  0.9527687296416938\n",
      "Correct:  0.990161783996502\n"
     ]
    }
   ],
   "source": [
    "#### Algorithm results\n",
    "get_accuracy(alg_v5, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML library\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data.label_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = vectorizer.fit_transform(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = x\n",
    "example_count = vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_count)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acuraccy_naive_byes():\n",
    "    \"\"\"\n",
    "    This functions prints sesults of the sk\n",
    "    \"\"\"\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "        s_correct = 0\n",
    "        h_correct = 0\n",
    "        spam = len(train_data.groupby(['true_category']).get_group('spam'))\n",
    "        ham = len(train_data.groupby(['true_category']).get_group('ham'))\n",
    "        len_of_data = len(train_data)\n",
    "        for i in range(len(predictions)):\n",
    "            prediction = predictions[i]\n",
    "            real_label = train_data['label_num'][i]\n",
    "            if int(prediction) == int(real_label):\n",
    "                # If prediction is correct we add 1\n",
    "                correct += 1\n",
    "                if int(prediction) == 1:\n",
    "                    # If the predicted label is spam and acutal label\n",
    "                    # is spam then we add to amount correct for spam\n",
    "                    s_correct += 1\n",
    "                elif int(prediction) == 0:\n",
    "                    # If the predicted label is ham and acutal label\n",
    "                    # is spam then we add to amount correct for ham\n",
    "                    h_correct += 1\n",
    "            elif int(prediction) != int(real_label):\n",
    "                incorrect +=1\n",
    "            \n",
    "        print(\"incorrect\", +incorrect/len_of_data)\n",
    "        print((s_correct+h_correct)/2)\n",
    "        print('Correct Ham: ', + h_correct/ham)\n",
    "        print('Correct Spam: ', + s_correct/spam)\n",
    "        print('Correct: ', + correct/len_of_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorrect 0.006996064713598601\n",
      "2271.0\n",
      "Correct Ham:  0.996969696969697\n",
      "Correct Spam:  0.9674267100977199\n",
      "Correct:  0.9930039352864014\n"
     ]
    }
   ],
   "source": [
    "get_acuraccy_naive_byes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Getting test data\n",
    "test_data = pd.read_csv(\"data/test\", sep=\"\\t\", names=[\"true_category\", \"message\", \"label_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488.5\n",
      "Correct Ham:  0.9907514450867052\n",
      "Correct Spam:  0.9022556390977443\n",
      "Correct:  0.9789579158316634\n"
     ]
    }
   ],
   "source": [
    "### Algorithm results with test data\n",
    "get_accuracy(alg_v5, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
